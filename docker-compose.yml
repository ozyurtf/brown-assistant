version: '3.8'

services:
  rag-app:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "${API_PORT}:${API_PORT}" 
      - "${STREAMLIT_PORT}:${STREAMLIT_PORT}" 
    environment:
      # OpenAI API Key - set this in your .env file or pass as environment variable
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - API_TOKEN=${API_TOKEN}
        
      # Optional: Control evaluation precomputation
      - PRECOMPUTE_EVAL=${PRECOMPUTE_EVAL}
      
      # API Configuration
      - API_BASE=http://${API_HOST}:${API_PORT}
      
      # Streamlit Configuration
      - STREAMLIT_SERVER_PORT=${STREAMLIT_PORT}
      - STREAMLIT_SERVER_ADDRESS=${STREAMLIT_HOST}
      
      # Python Configuration
      - PYTHONDONTWRITEBYTECODE=${PYTHONDONTWRITEBYTECODE}
      - PYTHONUNBUFFERED=${PYTHONUNBUFFERED}
      - TOKENIZERS_PARALLELISM=${TOKENIZERS_PARALLELISM}
    
    volumes:
      # Persist data files and vector store
      - ./files:/app/files
      - ./vector_store:/app/vector_store
      - ./logs:/app/logs
      
      # Optional: Mount .env file if you have one
      - ./.env:/app/.env
    
    restart: unless-stopped
    
    healthcheck:
      test: ["CMD", "sh", "-c", "curl -f http://localhost:${API_PORT}/docs"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    
    # Resource limits (adjust as needed)
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G
